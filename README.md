# TAP_CC


Early accident prediction using dashcam videos plays a crucial role in enhancing the safety of modern intelligent transportation systems. Accurately predicting accidents in advance can significantly reduce traffic accidents and improve overall road safety. However, despite extensive research efforts to capture more visual information by employing different feature extraction methods within the same frame, the consistency between features within the same frame and the discrepancy between features across different frames have not been sufficiently emphasized. To address this critical issue, we introduce contrastive learning into the field of accident prediction and propose a novel feature fusion module for the deep integration of diverse features. Our method treats features from the same frame as positive pairs and those from different frames as negative pairs. This approach amplifies the similarity of positive pairs while increasing the dissimilarity of negative pairs, thus enhancing the model's ability to capture the consistency of data within the same frame and improving the overall prediction performance. Additionally, we redefine the accident prediction task by converting it into an anomaly score regression problem using soft labels. This redefinition allows the model to better quantify the likelihood of an accident, offering a more nuanced and accurate prediction. We evaluate our method comprehensively on two publicly available Dashcam Accident Dataset (DAD) and Car Crash Dataset(CCD) datasets to assess its performance. The results demonstrate that our method outperforms state-of-the-art accident prediction approaches, highlighting its potential for practical applications.

The code could be available after the paper is published
